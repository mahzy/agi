{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahzy/agi/blob/main/LangChain_AGI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain-AGI\n",
        "This notebook is a somewhat facetious attempt at using LangChain to approximate/reach AGI. It consists of an agent (backed by a language model) using tools to answer/execute questions.\n",
        "\n",
        "There are several choices to be made:\n",
        "\n",
        "- What language model to use?\n",
        "- What agent to use?\n",
        "- What tools to use?\n",
        "\n",
        "We will keep this notebook up-to-date with what we believe to be the best combination of all of those, where \"best\" is measured as the highest chance of achieving AGI.\n",
        "\n",
        "At this moment, the answers to those questions are:\n",
        "\n",
        "- What language model to use: OpenAI's `text-davinci-003`\n",
        "- What agent to use: `zero-shot-react-agent`\n",
        "- What tools to use: all of them!"
      ],
      "metadata": {
        "id": "l9PfOJAr_Qth"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install and Initialize Agent"
      ],
      "metadata": {
        "id": "e00BbhVaaiRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain openai google-search-results"
      ],
      "metadata": {
        "id": "Y0nT-cEKZ7lT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37d3c33b-70ad-44b6-b241-741eb00bab6e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.46-py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 8.7 MB/s \n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-0.25.0.tar.gz (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 3.3 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.1.tar.gz (11 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.8/dist-packages (from langchain) (1.21.6)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.8/dist-packages (from langchain) (2.23.0)\n",
            "Requirement already satisfied: PyYAML<7,>=6 in /usr/local/lib/python3.8/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<2,>=1 in /usr/local/lib/python3.8/dist-packages (from langchain) (1.4.45)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.8/dist-packages (from langchain) (1.10.2)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic<2,>=1->langchain) (4.4.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2->langchain) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2->langchain) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2->langchain) (3.0.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from SQLAlchemy<2,>=1->langchain) (2.0.1)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.8/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.8/dist-packages (from openai) (3.0.10)\n",
            "Collecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.5.2.221213-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 71.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.8/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Collecting types-pytz>=2022.1.1\n",
            "  Downloading types_pytz-2022.7.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Building wheels for collected packages: openai, google-search-results\n",
            "  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.25.0-py3-none-any.whl size=55880 sha256=7a2cffae934d2be0ad9a80a01d1f6561fb1c402f280d18571463f0dd8dc03465\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/92/33/6f57c7aae0b16875267999a50570e81f15eecec577ebe05a2e\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.1-py3-none-any.whl size=25788 sha256=da4b584cc3a8e08566d510ca05b014c0d123e2b26f0a01e9c774b4df44e6d2ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/58/9e/3d89ebff948ef9ce0a6e056a8279c1f93c76993387766f8387\n",
            "Successfully built openai google-search-results\n",
            "Installing collected packages: types-pytz, pandas-stubs, openai, langchain, google-search-results\n",
            "Successfully installed google-search-results-2.4.1 langchain-0.0.46 openai-0.25.0 pandas-stubs-1.5.2.221213 types-pytz-2022.7.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "os.environ[\"SERPAPI_API_KEY\"] = \"\"\n",
        "news_api_key = \"\"\n",
        "tmdb_bearer_token = \"\""
      ],
      "metadata": {
        "id": "zyPFIUz8APec"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bUSY4CRo_Jg4"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import load_tools, initialize_agent, get_all_tool_names\n",
        "from langchain.llms import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tool_names = get_all_tool_names()\n",
        "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)\n",
        "tools = load_tools(tool_names, llm=llm, news_api_key=news_api_key, tmdb_bearer_token=tmdb_bearer_token)\n",
        "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
      ],
      "metadata": {
        "id": "cSxx-i83AcDB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "42ef6782-d72f-4216-c672-18375392a918"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValidationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-4faa306ad37d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtool_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_tool_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-davinci-003\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtools\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_tools\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnews_api_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnews_api_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmdb_bearer_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtmdb_bearer_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"zero-shot-react-description\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pydantic/main.cpython-38-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for OpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test the Agent Out"
      ],
      "metadata": {
        "id": "wHXGSyGcaexi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"How many people live in canada?\")"
      ],
      "metadata": {
        "id": "d5H-KfVQAoYM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "4858157a-f6b9-4c1b-e753-4377c4ae51a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to find a source of information that can answer this question.\n",
            "Action: Search\n",
            "Action Input: \"how many people live in canada\"\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mCanada 2020 population is estimated at 37,742,154 people at mid year according to UN data. Canada population is equivalent to 0.48% of the total world ...\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: 37,742,154 people\u001b[0m\n",
            "\u001b[1m> Finished AgentExecutor chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'37,742,154 people'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"What is 13**.3?\")"
      ],
      "metadata": {
        "id": "72PJfRzjApdK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "55424042-1f67-47db-d334-7b5734b6936c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to calculate this\n",
            "Action: Calculator\n",
            "Action Input: 13**.3\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mAnswer: 2.1544346900318834\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: 2.1544346900318834\u001b[0m\n",
            "\u001b[1m> Finished AgentExecutor chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1544346900318834'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"How much did it rain in SF today?\")"
      ],
      "metadata": {
        "id": "m62_3Yq5ApaT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "a8f549c0-b098-4455-a09a-fe19459cecfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to find out the weather in SF today\n",
            "Action: Open Meteo API\n",
            "Action Input: How much did it rain in SF today?\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m It did not rain in SF today (December 19th, 2022).\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: It did not rain in SF today (December 19th, 2022).\u001b[0m\n",
            "\u001b[1m> Finished AgentExecutor chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'It did not rain in SF today (December 19th, 2022).'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"get me information about the movie 'Avatar'\")"
      ],
      "metadata": {
        "id": "0_Lj1iHBApW4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "dd861c51-b84c-4fe4-a6c2-962c774e11a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use an API to get this information\n",
            "Action: TMDB API\n",
            "Action Input: \"What is the plot of Avatar?\"\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3m The response from the API contains 57 movies related to the search query \"Avatar\". The first result is the movie \"Avatar\" (2009) which has an overview of \"In the 22nd century, a paraplegic Marine is dispatched to the moon Pandora on a unique mission, but becomes torn between following orders and protecting an alien civilization.\"\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: In the 22nd century, a paraplegic Marine is dispatched to the moon Pandora on a unique mission, but becomes torn between following orders and protecting an alien civilization.\u001b[0m\n",
            "\u001b[1m> Finished AgentExecutor chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In the 22nd century, a paraplegic Marine is dispatched to the moon Pandora on a unique mission, but becomes torn between following orders and protecting an alien civilization.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"what are the top tech headlines in the US.\")"
      ],
      "metadata": {
        "id": "XN7IhYkWApJr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "f5241b47-7628-4f33-dc82-0ff361d10497"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to find a way to get the top tech headlines in the US.\n",
            "Action: Search\n",
            "Action Input: \"top tech headlines US\"\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mTop News Stories\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to get the actual headlines\n",
            "Action: News API\n",
            "Action Input: \"What are the top tech headlines in the US?\"\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m This response from the API contains two articles about top tech headlines in the US. The first article is about Harold Edgerton's photograph of a bullet passing through an apple and how it changed photography forever. The second article is about video game pioneer John Carmack resigning from his consulting position at Meta.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The top tech headlines in the US are about Harold Edgerton's photograph of a bullet passing through an apple and how it changed photography forever, and about video game pioneer John Carmack resigning from his consulting position at Meta.\u001b[0m\n",
            "\u001b[1m> Finished AgentExecutor chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The top tech headlines in the US are about Harold Edgerton's photograph of a bullet passing through an apple and how it changed photography forever, and about video game pioneer John Carmack resigning from his consulting position at Meta.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"On the desk, you see two blue booklets, two purple booklets, and two yellow pairs of sunglasses - if I remove all the pairs of sunglasses from the desk, how many purple items remain on it?\"\n",
        "agent.run(question)"
      ],
      "metadata": {
        "id": "dMBblkgWAz8k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "a2880d1f-107e-4b64-9c84-a98e7ffd9958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to reason about the position and color attributes of the objects on the desk.\n",
            "Action: PAL-COLOR-OBJ\n",
            "Action Input: On the desk, there are two blue booklets, two purple booklets, and two yellow pairs of sunglasses. If I remove all the pairs of sunglasses from the desk, how many purple items remain on it?\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m2\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: 2 purple items remain on the desk.\u001b[0m\n",
            "\u001b[1m> Finished AgentExecutor chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2 purple items remain on the desk.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}